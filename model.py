# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rmoug7i7wwW25Kk4H9QnuZCtEEr14qe6
"""

!pip install torch torchvision torchaudio --quiet
!pip install transformers accelerate --quiet
!pip install diffusers --quiet
!pip install colorthief opencv-python pillow --quiet

from PIL import Image
import json
import os

folder_path = "./NFT49"  # Set your folder

# Auto-detect JSON and image
json_file, image_file = None, None
for file_name in os.listdir(folder_path):
    if file_name.endswith(".json"):
        json_file = os.path.join(folder_path, file_name)
    if file_name.endswith((".png", ".jpg", ".jpeg")):
        image_file = os.path.join(folder_path, file_name)

assert json_file and image_file, "Missing JSON or image!"

# Load report JSON
with open(json_file, 'r') as f:
    report_json = json.load(f)

# Load NFT image
nft_image = Image.open(image_file)
nft_image.show()

# Extract details
primary_hex = [color['HEX'] for color in report_json["Primary Colors"]]
secondary_hex = [color['HEX'] for color in report_json["Secondary Colors"]]
theme = report_json["Detected NFT Theme"]
shapes = report_json["Number of Detected Shapes"]

print(primary_hex, secondary_hex, theme, shapes)

from transformers import Blip2Processor, Blip2ForConditionalGeneration
import torch

processor = Blip2Processor.from_pretrained("Salesforce/blip2-flan-t5-xl", trust_remote_code=True)
model = Blip2ForConditionalGeneration.from_pretrained("Salesforce/blip2-flan-t5-xl", trust_remote_code=True, torch_dtype=torch.float16).eval().cuda()

inputs = processor(images=nft_image, return_tensors="pt").to("cuda", torch.float16)
out = model.generate(**inputs, max_new_tokens=50)
caption = processor.decode(out[0], skip_special_tokens=True)

print("Focal Element:", caption)

from transformers import AutoTokenizer, AutoModelForCausalLM

model_name = "teknium/OpenHermes-2-Mistral-7B"

tokenizer = AutoTokenizer.from_pretrained(model_name)

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype=torch.float16,
    offload_folder="./offload"  # ADD THIS LINE
).eval()

prompt = f"""
You are a fashion AI. Given the following NFT details:
- Primary colors: {primary_hex}
- Secondary colors: {secondary_hex}
- Theme: {theme}
- Focal Description: {caption}
- Shape complexity: {shapes} shapes

Generate a design proposal for a hoodie, including:
1. Chest print using Centered Extraction.
2. Back print using Full-Screen Expansion.
3. Sleeve embroidery element.
4. Neck crow backside branding color.

Output ONLY in JSON format.
"""

inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=600)
result = tokenizer.decode(outputs[0], skip_special_tokens=True)

print("LLM Output:\n", result)

import re
import json

# Extract JSON part only from LLM output
json_start = result.find("{")
design_json_str = result[json_start:]
design_data = json.loads(design_json_str)

print("Parsed Design Proposal:", json.dumps(design_data, indent=2))

# Dynamically build prompt for Stable Diffusion
design_prompt = f"""
A realistic hoodie design featuring:
- Chest: {design_data['chest_print']['description']}
- Back: {design_data['back_print']['description']}
- Sleeve: {design_data['sleeve_embroidery']['description']}
- Neckline: {design_data['neck_crow_backside']['description']}
Primary Colors: {primary_hex}, Secondary Colors: {secondary_hex}
Front and back view, modern realistic look.
"""
print("Final Prompt:\n", design_prompt)

from diffusers import StableDiffusionPipeline

pipe = StableDiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16).to("cuda")

# Generate hoodie mockup
final_image = pipe(design_prompt).images[0]
final_image.save("final_hoodie_mockup.png")
final_image.show()